{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Experiment Results (Reduced Depths):\n",
      "   max_depth accuracy  execution_time precision   recall      f1\n",
      "0          3   86.67%  0.1502 seconds    86.67%  100.00%  92.86%\n",
      "1          5   81.67%  0.1868 seconds    87.27%   92.31%  89.72%\n",
      "2          7   84.17%  0.1926 seconds    87.61%   95.19%  91.24%\n",
      "3          9   76.67%  0.1945 seconds    86.54%   86.54%  86.54%\n",
      "\n",
      "Best performing model:\n",
      "{'max_depth': 3, 'accuracy': '86.67%', 'execution_time': '0.1502 seconds', 'precision': '86.67%', 'recall': '100.00%', 'f1': '92.86%'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"./data/Fraud_check.csv\")\n",
    "\n",
    "# Create a 'Risk' column based on Taxable.Income --  0 = Risky, 1 = Good\n",
    "df[\"Risk\"] = np.where(df[\"Taxable.Income\"] <= 30000, 0, 1)\n",
    "\n",
    "# Drop unnecessary columns (City.Population and Taxable.Income)\n",
    "df = df.drop(columns=[\"City.Population\", \"Taxable.Income\"])\n",
    "\n",
    "# Convert categorical columns into numerical format (binary or multiple values)\n",
    "df[\"Undergrad\"] = df[\"Undergrad\"].map({\"YES\": 1, \"NO\": 0})\n",
    "df[\"Marital.Status\"] = df[\"Marital.Status\"].map(\n",
    "    {\"Single\": 0, \"Married\": 1, \"Divorced\": 2}\n",
    ")\n",
    "df[\"Urban\"] = df[\"Urban\"].map({\"YES\": 1, \"NO\": 0})\n",
    "\n",
    "# Separate the features (X) and target (Y)\n",
    "X = df.drop(columns=[\"Risk\"])  # Features\n",
    "Y = df[\"Risk\"]  # Target (Risk)\n",
    "\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "train_size = int(0.8 * len(df))\n",
    "X_train, X_test = X[:train_size], X[train_size:]  # First 80% for training\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]  # Remaining 20% for testing\n",
    "\n",
    "\n",
    "# GINI Index calculation\n",
    "def gini_index(groups, classes):\n",
    "    total_samples = sum([len(group) for group in groups])  # Total number of samples\n",
    "\n",
    "    gini = 0.0  # Initialize GINI index\n",
    "    for group in groups:\n",
    "        size = len(group)\n",
    "        if size == 0:  # If group is empty, skip it\n",
    "            continue\n",
    "\n",
    "        # Calculate the score for the group\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            proportion = [row[-1] for row in group].count(class_val) / size\n",
    "            score += proportion * proportion\n",
    "\n",
    "        # GINI for this group, weighted by its size\n",
    "        gini += (1.0 - score) * (size / total_samples)\n",
    "\n",
    "    return gini\n",
    "\n",
    "\n",
    "# Function to split the dataset based on a feature and its value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()  # Create empty lists for left and right branches\n",
    "    for row in dataset:\n",
    "        if (\n",
    "            row[index] < value\n",
    "        ):  # If the feature's value is less than the split value, go left\n",
    "            left.append(row)\n",
    "        else:  # Otherwise, go right\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "\n",
    "# Find the best split based on GINI index\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))  # Get unique classes (0, 1)\n",
    "    best_index, best_value, best_gini, best_groups = (\n",
    "        999,\n",
    "        999,\n",
    "        999,\n",
    "        None,\n",
    "    )  # Initialize best values\n",
    "\n",
    "    for index in range(len(dataset[0]) - 1):  # For each feature\n",
    "        for row in dataset:  # For each row in dataset\n",
    "            groups = test_split(index, row[index], dataset)  # Split the dataset\n",
    "            gini = gini_index(groups, class_values)  # Calculate GINI index\n",
    "            if gini < best_gini:  # If GINI is lower, update the best split\n",
    "                best_index, best_value, best_gini, best_groups = (\n",
    "                    index,\n",
    "                    row[index],\n",
    "                    gini,\n",
    "                    groups,\n",
    "                )\n",
    "\n",
    "    return {\"index\": best_index, \"value\": best_value, \"groups\": best_groups}\n",
    "\n",
    "\n",
    "# Create a terminal node (decide on the final class if no more splitting is possible)\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]  # Collect class labels (Risky or Good)\n",
    "    return max(set(outcomes), key=outcomes.count)  # Return the most common class\n",
    "\n",
    "\n",
    "# Recursive function to split the node and build the tree\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node[\"groups\"]  # Get the left and right groups of data\n",
    "    del node[\"groups\"]  # Remove the groups from the node after splitting\n",
    "\n",
    "    # Check if no more splitting is needed (either side is empty)\n",
    "    if not left or not right:\n",
    "        node[\"left\"] = node[\"right\"] = to_terminal(left + right)\n",
    "        return\n",
    "\n",
    "    # If max depth is reached, stop splitting\n",
    "    if depth >= max_depth:\n",
    "        node[\"left\"], node[\"right\"] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "\n",
    "    # Split the left side of the tree\n",
    "    if len(left) <= min_size:\n",
    "        node[\"left\"] = to_terminal(left)\n",
    "    else:\n",
    "        node[\"left\"] = get_split(left)\n",
    "        split(node[\"left\"], max_depth, min_size, depth + 1)\n",
    "\n",
    "    # Split the right side of the tree\n",
    "    if len(right) <= min_size:\n",
    "        node[\"right\"] = to_terminal(right)\n",
    "    else:\n",
    "        node[\"right\"] = get_split(right)\n",
    "        split(node[\"right\"], max_depth, min_size, depth + 1)\n",
    "\n",
    "\n",
    "# Build the decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)  # Get the root node\n",
    "    split(root, max_depth, min_size, 1)  # Start recursive splitting\n",
    "    return root\n",
    "\n",
    "\n",
    "# Make a prediction for a single row of data\n",
    "def predict(node, row):\n",
    "    if (\n",
    "        row[node[\"index\"]] < node[\"value\"]\n",
    "    ):  # If row's value is less than the node's split value, go left\n",
    "        if isinstance(\n",
    "            node[\"left\"], dict\n",
    "        ):  # If the left branch is another node, recurse\n",
    "            return predict(node[\"left\"], row)\n",
    "        else:\n",
    "            return node[\"left\"]  # Otherwise, return the predicted class\n",
    "    else:\n",
    "        if isinstance(\n",
    "            node[\"right\"], dict\n",
    "        ):  # If the right branch is another node, recurse\n",
    "            return predict(node[\"right\"], row)\n",
    "        else:\n",
    "            return node[\"right\"]  # Otherwise, return the predicted class\n",
    "\n",
    "\n",
    "# Calculate Confusion Matrix elements manually\n",
    "def confusion_matrix_manual(actual, predicted):\n",
    "    TP = sum((actual == 1) & (predicted == 1))  # True Positives\n",
    "    TN = sum((actual == 0) & (predicted == 0))  # True Negatives\n",
    "    FP = sum((actual == 0) & (predicted == 1))  # False Positives\n",
    "    FN = sum((actual == 1) & (predicted == 0))  # False Negatives\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score manually\n",
    "def precision_recall_f1(tp, fp, fn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = (\n",
    "        2 * (precision * recall) / (precision + recall)\n",
    "        if (precision + recall) > 0\n",
    "        else 0\n",
    "    )\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "# Convert training and test data to lists\n",
    "train_data = np.column_stack([X_train.values, Y_train.values]).tolist()\n",
    "test_data = np.column_stack([X_test.values, Y_test.values]).tolist()\n",
    "\n",
    "\n",
    "# Limiting the max_depth values to a smaller set for faster experimentation\n",
    "limited_max_depths = [3, 5, 7, 9]\n",
    "min_size = 10\n",
    "\n",
    "# Running the experiment\n",
    "results = []\n",
    "\n",
    "for depth in limited_max_depths:\n",
    "    start_time = time.time()  # Start timer\n",
    "    tree = build_tree(train_data, depth, min_size)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = [predict(tree, row) for row in test_data]\n",
    "\n",
    "    # Call the function on your actual and predicted values\n",
    "    TP, TN, FP, FN = confusion_matrix_manual(np.array(Y_test), np.array(predictions))\n",
    "\n",
    "    precision, recall, f1 = precision_recall_f1(TP, FP, FN)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = sum(\n",
    "        [pred == row[-1] for pred, row in zip(predictions, test_data)]\n",
    "    ) / len(test_data)\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"max_depth\": depth,\n",
    "            \"accuracy\": f\"{accuracy * 100:.2f}%\",\n",
    "            \"execution_time\": f\"{execution_time:.4f} seconds\",\n",
    "            \"precision\": f\"{precision * 100:.2f}%\",\n",
    "            \"recall\": f\"{recall * 100:.2f}%\",\n",
    "            \"f1\": f\"{f1 * 100:.2f}%\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Displaying the results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Decision Tree Experiment Results (Reduced Depths):\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "# Showing the best performing model\n",
    "best_result = max(results, key=lambda x: x[\"accuracy\"])\n",
    "print(\"\\nBest performing model:\")\n",
    "print(best_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
